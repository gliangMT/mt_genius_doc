Search.setIndex({"docnames": ["index", "vllm/index", "vllm/vllm_mtt"], "filenames": ["index.rst", "vllm\\index.rst", "vllm\\vllm_mtt.md"], "titles": ["Welcome to Moore Threads AI Doc!", "&lt;no title&gt;", "vLLM_MTTransformer"], "terms": {"mttransform": [0, 1, 2], "llm": 2, "mt": 2, "gpu": 2, "driver": 2, "kuae": 2, "mtbio": 2, "qy2": 2, "v3": 2, "code": 2, "docker": 2, "run": 2, "it": 2, "privileg": 2, "net": 2, "host": 2, "name": 2, "vllm_mtt_test": 2, "workspac": 2, "data": 2, "env": 2, "mthreads_visible_devic": 2, "all": 2, "shm": 2, "size": 2, "80g": 2, "sh": 2, "harbor": 2, "mthread": 2, "com": 2, "ai": 2, "musa": 2, "pytorch": 2, "transform": 2, "v0": 2, "bin": 2, "bash": 2, "core": 2, "zlidc": 2, "30003": 2, "tag": 2, "llama2": 2, "7b": 2, "13b": 2, "70b": 2, "mistral": 2, "qwen": 2, "14b": 2, "72b": 2, "qwen1": 2, "32b": 2, "110b": 2, "moe": 2, "qwen2": 2, "5b": 2, "chatglm2": 2, "6b": 2, "baichuan": 2, "yayi2": 2, "30b": 2, "yayi": 2, "export": 2, "vllm_no_usage_stat": 2, "bug": 2, "engin": 2, "argument": 2, "sampl": 2, "paramet": 2, "mttansform": 2, "float16": 2, "ray": 2, "rope": 2, "lora": 2, "fine": 2, "tune": 2, "model": 2, "convert_weigh": 2, "devic": 2, "tensor": 2, "parallel": 2, "convert": 2, "weight": 2, "kv": 2, "cach": 2, "dtype": 2, "auto": 2, "pipelin": 2, "block": 2, "64": 2, "max": 2, "num": 2, "seq": 2, "128": 2, "batch": 2, "token": 2, "len": 2, "python": 2, "convert_weight": 2, "in_fil": 2, "llama": 2, "chat": 2, "hf": 2, "fp16": 2, "saved_dir": 2, "models_convert": 2, "tp1": 2, "weight_data_typ": 2, "model_typ": 2, "para": 2, "arch": 2, "mp_22": 2, "huggingfac": 2, "in": 2, "file": 2, "fp32": 2, "bf16": 2, "type": 2, "chatglm3": 2, "baichuan2": 2, "mp": 2, "22": 2, "tp": 2, "usag": 2, "original_model_path": 2, "tp_size": 2, "vllm_mtt": 2, "pythonpath": 2, "home": 2, "generate_llama2": 2, "py": 2, "import": 2, "from": 2, "samplingparam": 2, "path": 2, "gpu_memory_util": 2, "tensor_parallel_s": 2, "block_siz": 2, "max_num_seq": 2, "max_model_len": 2, "2048": 2, "max_num_batched_token": 2, "print": 2, "the": 2, "output": 2, "prompt": 2, "inst": 2, "hello": 2, "hi": 2, "who": 2, "are": 2, "you": 2, "am": 2, "going": 2, "to": 2, "pari": 2, "where": 2, "should": 2, "go": 2, "what": 2, "is": 2, "your": 2, "come": 2, "sampling_param": 2, "temperatur": 2, "top_p": 2, "95": 2, "max_token": 2, "40": 2, "generat": 2, "for": 2, "idx": 2, "enumer": 2, "generated_text": 2, "text": 2, "ngener": 2, "generate_chat": 2, "ckpt": 2, "checkpoint_path": 2, "tp2": 2, "async_chat_llama2": 2, "asyncio": 2, "time": 2, "asyncllmengin": 2, "asyncenginearg": 2, "engine_arg": 2, "enforce_eag": 2, "true": 2, "disable_log_stat": 2, "enable_prefix_cach": 2, "initi": 2, "and": 2, "request": 2, "facebook": 2, "opt": 2, "125m": 2, "from_engine_arg": 2, "def": 2, "build_prompt": 2, "return": 2, "async": 2, "generate_stream": 2, "history_text": 2, "while": 2, "input": 2, "if": 2, "stop": 2, "break": 2, "results_gener": 2, "1024": 2, "request_id": 2, "monoton": 2, "previous_text": 2, "ngeneratetext": 2, "request_output": 2, "end": 2, "flush": 2, "option": 2, "get_token": 2, "eos_token": 2, "finish": 2, "dialog": 2, "streaming_chat": 2, "openai": 2, "api": 2, "server": 2, "entrypoint": 2, "api_serv": 2, "trust": 2, "remot": 2, "pp": 2, "4096": 2, "disabl": 2, "log": 2, "stat": 2, "memori": 2, "util": 2, "curl": 2, "http": 2, "8000": 2, "v1": 2, "complet": 2, "content": 2, "applic": 2, "json": 2, "messag": 2, "role": 2, "system": 2, "help": 2, "assist": 2, "user": 2, "won": 2, "world": 2, "seri": 2, "2020": 2, "id": 2, "cmpl": 2, "8062e4a30b1f452885f65d60a0d54591": 2, "object": 2, "creat": 2, "1724259639": 2, "choic": 2, "index": 2, "los": 2, "angel": 2, "dodger": 2, "logprob": 2, "null": 2, "finish_reason": 2, "stop_reason": 2, "prompt_token": 2, "32": 2, "total_token": 2, "49": 2, "completion_token": 2, "17": 2, "sharegpt": 2, "unfilt": 2, "clean": 2, "split": 2, "gpt": 2, "cd": 2, "dataset": 2, "wget": 2, "https": 2, "co": 2, "anon8231489123": 2, "sharegpt_vicuna_unfilt": 2, "resolv": 2, "main": 2, "sharegpt_v3_unfiltered_cleaned_split": 2, "mtt_benchmark": 2, "benchmark_offlin": 2, "mkdir": 2, "bench_result": 2, "benchmark_thoughput": 2, "train": 2, "jsonl": 2, "save": 2, "result": 2, "dir": 2, "7000": 2, "benchmark_serv": 2, "step1_server_start": 2, "case": 2, "step2_test": 2, "serving_result": 2, "csv": 2, "result_convert": 2, "in_path": 2, "offlin": 2, "serv": 2, "output_path": 2, "offline_result": 2, "perf_config": 2, "model_nam": 2, "tp8": 2, "prefill_token_len": 2, "256": 2, "512": 2, "decode_token_len": 2, "perf_test": 2, "perf_data": 2, "combine_ret": 2, "success": 2, "latenc": 2, "elaps": 2, "req": 2, "throughput": 2, "tok": 2, "succes": 2, "1000": 2, "durat": 2, "total": 2, "mean": 2, "ttft": 2, "ms": 2, "median": 2, "p99": 2, "99": 2, "tpot": 2, "vllm": [0, 1], "benchmark": 0, "mtt": 0, "perf": 0, "vllm_mttransform": []}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"welcom": 0, "to": 0, "moor": 0, "thread": 0, "ai": 0, "doc": 0, "document": [], "indic": 0, "and": 0, "tabl": 0, "vllm_mttransform": 2, "vllm": 2, "benchmark": 2, "mtt": 2, "perf": 2, "content": [0, 1]}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Contents:": [[1, null], [0, null]], "Welcome to Moore Threads AI Doc!": [[0, "welcome-to-moore-threads-ai-doc"]], "Indices and tables": [[0, "indices-and-tables"]], "vLLM_MTTransformer": [[2, "vllm-mttransformer"]], "0.\u73af\u5883\u4f9d\u8d56": [[2, "id1"]], "1.\u542f\u52a8\u5bb9\u5668": [[2, "id2"]], "2.\u652f\u6301\u6a21\u578b\u5217\u8868": [[2, "id3"]], "3.vLLM\u53c2\u6570\u914d\u7f6e": [[2, "vllm"]], "4.\u5feb\u901f\u5f00\u59cb": [[2, "id4"]], "5.Benchmark": [[2, "benchmark"]], "\u524d\u7f6e\u51c6\u5907": [[2, "id5"]], "\u8fd0\u884c\u6d4b\u8bd5": [[2, "id6"]], "6.mtt\u6027\u80fd\u6d4b\u8bd5": [[2, "mtt"]], "\u65b0\u5efa\u914d\u7f6e\u6587\u4ef6-\u793a\u4f8b": [[2, "id7"]], "\u6267\u884cperf\u6d4b\u8bd5": [[2, "perf"]], "\u67e5\u9a8c\u7ed3\u679c": [[2, "id8"]], "7.\u9644\u5f55": [[2, "id9"]], "Benchmark\u79bb\u7ebf\u7ed3\u679c\u89e3\u91ca": [[2, "id10"]], "Benchmark\u5728\u7ebf\u7ed3\u679c\u89e3\u91ca": [[2, "id11"]]}, "indexentries": {}})